{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f898591",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "No normalization for NumAmideBonds. Feature removed!\n",
      "No normalization for NumAtomStereoCenters. Feature removed!\n",
      "No normalization for NumBridgeheadAtoms. Feature removed!\n",
      "No normalization for NumHeterocycles. Feature removed!\n",
      "No normalization for NumSpiroAtoms. Feature removed!\n",
      "No normalization for NumUnspecifiedAtomStereoCenters. Feature removed!\n",
      "No normalization for Phi. Feature removed!\n",
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (/mnt/Supermicro/data2/test-syntelly/.deepchem/lib/python3.11/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/mnt/Supermicro/data2/test-syntelly/.deepchem/lib/python3.11/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "Skipped loading some PyTorch models, missing a dependency. No module named 'tensorflow'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "\n",
    "import json\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "import deepchem as dc\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "import torch \n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ce22d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.experiment_config import config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00de376c",
   "metadata": {},
   "source": [
    "# Graph Conv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351b6b46",
   "metadata": {},
   "source": [
    "Построим простой эксперимент с помощью deepchem, чтобы улучшить результаты с использованием GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2ec66ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 11485, After cleaning: 11484\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(config.DATA_PATH / \"melt_clean.csv\")\n",
    "\n",
    "def is_valid_smiles(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    return mol is not None and mol.GetNumAtoms() > 1\n",
    "\n",
    "df_clean = df[df[\"canonical_smiles\"].apply(is_valid_smiles)].copy()\n",
    "print(f\"Before: {len(df)}, After cleaning: {len(df_clean)}\")\n",
    "df_clean.to_csv(config.DATA_PATH / \"melt_clean_filtered.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb703717",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = dc.data.CSVLoader(tasks=[\"melt_value\"], \n",
    "                  feature_field=\"canonical_smiles\",\n",
    "                  id_field='index',\n",
    "                  featurizer= dc.feat.MolGraphConvFeaturizer(use_edges=True))\n",
    "\n",
    "dataset = loader.create_dataset(config.DATA_PATH / 'melt_clean_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf92dc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphData(node_features=[53, 30], edge_index=[2, 126], edge_features=[126, 11])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "806f9c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/Supermicro/data2/test-syntelly/.deepchem/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started fold: 1\n",
      "Fold 0 | Val MSE: 4207.1428 | Test MSE: 4540.8182\n",
      "Started fold: 2\n",
      "Fold 1 | Val MSE: 3934.1291 | Test MSE: 4989.6489\n",
      "Started fold: 3\n",
      "Fold 2 | Val MSE: 5231.6817 | Test MSE: 14763.9235\n",
      "Started fold: 4\n",
      "Fold 3 | Val MSE: 4877.7864 | Test MSE: 4234.8061\n",
      "Started fold: 5\n",
      "Fold 4 | Val MSE: 4251.5373 | Test MSE: 5399.3662\n"
     ]
    }
   ],
   "source": [
    "from deepchem.models.torch_models import GCN, GCNModel\n",
    "metric = dc.metrics.Metric(dc.metrics.mean_squared_error, mode=\"regression\")\n",
    "results = []\n",
    "N_EPOCHES = 5\n",
    "split_data = json.load((config.DATA_PATH / 'melt_split.json').open())\n",
    "for fold in range(5):\n",
    "    split_dict = split_data[fold]\n",
    "    train_ids, val_ids, test_ids = [], [], []\n",
    "    for index, idx in enumerate(dataset.ids):\n",
    "        split = split_dict.get(str(idx))\n",
    "        if split == \"train\":\n",
    "            train_ids.append(index)\n",
    "        elif split == \"val\":\n",
    "            val_ids.append(index)\n",
    "        elif split == \"test\":\n",
    "            test_ids.append(index)\n",
    "\n",
    "    train_dataset = dataset.select(train_ids)\n",
    "    val_dataset   = dataset.select(val_ids)\n",
    "    test_dataset  = dataset.select(test_ids)\n",
    "\n",
    "\n",
    "    model = GCNModel(\n",
    "        n_tasks=1,\n",
    "        mode=\"regression\",\n",
    "        graph_conv_layers=[64, 128, 128, 64], \n",
    "        activation=torch.nn.LeakyReLU(),\n",
    "        batchnorm=True,\n",
    "        dropout=0.2,\n",
    "        predictor_dropout=0.2,\n",
    "        batch_size=32,\n",
    "        learning_rate=1e-3,\n",
    "        device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    )\n",
    "    print(f'Started fold: {fold+1}')\n",
    "    model.fit(train_dataset, nb_epoch=N_EPOCHES)\n",
    "\n",
    "    val_score = model.evaluate(val_dataset, [metric])\n",
    "    test_score = model.evaluate(test_dataset, [metric])\n",
    "    \n",
    "    print(f\"Fold {fold} | Val MSE: {val_score['mean_squared_error']:.4f} | Test MSE: {test_score['mean_squared_error']:.4f}\")\n",
    "    results.append((val_score, test_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c28c4227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cross-Validation Summary ===\n",
      "Validation MSE: Mean = 4500.4555, STD = 478.7042\n",
      "Test MSE:       Mean = 6785.7126, STD = 4008.6488\n"
     ]
    }
   ],
   "source": [
    "val_mse = [r[0]['mean_squared_error'] for r in results]\n",
    "test_mse = [r[1]['mean_squared_error'] for r in results]\n",
    "\n",
    "print(\"\\n=== Cross-Validation Summary ===\")\n",
    "print(f\"Validation MSE: Mean = {np.mean(val_mse):.4f}, STD = {np.std(val_mse):.4f}\")\n",
    "print(f\"Test MSE:       Mean = {np.mean(test_mse):.4f}, STD = {np.std(test_mse):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac575c80",
   "metadata": {},
   "source": [
    "# Custom GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b6698b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "No normalization for NumAmideBonds. Feature removed!\n",
      "No normalization for NumAtomStereoCenters. Feature removed!\n",
      "No normalization for NumBridgeheadAtoms. Feature removed!\n",
      "No normalization for NumHeterocycles. Feature removed!\n",
      "No normalization for NumSpiroAtoms. Feature removed!\n",
      "No normalization for NumUnspecifiedAtomStereoCenters. Feature removed!\n",
      "No normalization for Phi. Feature removed!\n",
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'dgl'\n",
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (/mnt/Supermicro/data2/test-syntelly/.torch/lib/python3.11/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "Skipped loading some PyTorch models, missing a dependency. No module named 'tensorflow'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch_geometric.nn import GCNConv, BatchNorm, global_mean_pool, Sequential\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset, Dataset\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import deepchem as dc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import mlflow\n",
    "import json\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from config.experiment_config import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a8c7046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "def set_seed(SEED):\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "set_seed(config.RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3c6ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = pd.read_csv(config.DATA_PATH / \"melt_clean_filtered.csv\")\n",
    "# dataset.iloc[8247]['melt_value']\n",
    "\n",
    "# smiles = df[df['index'] == 9648]['canonical_smiles'].values[0]\n",
    "# smiles\n",
    "\n",
    "# featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "# featurizer.featurize(smiles)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1240b71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['index'] == 9648]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d27c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeltDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super(MeltDataset, self).__init__()\n",
    "        self.featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "        self.dataset = pd.read_csv(config.DATA_PATH / \"melt_clean_filtered.csv\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            smiles = self.dataset.iloc[index]['canonical_smiles']\n",
    "            value = self.dataset.iloc[index]['melt_value']\n",
    "            data = self.featurizer.featurize(smiles)[0]\n",
    "        except IndexError:\n",
    "            print(index)\n",
    "        \n",
    "\n",
    "        return Data(\n",
    "            x=torch.tensor(data.node_features, dtype=torch.float32),\n",
    "            y=torch.tensor(value, dtype=torch.float32),\n",
    "            edge_index=torch.tensor(data.edge_index, dtype=torch.int32),\n",
    "            edge_attr=torch.tensor(data.edge_features, dtype=torch.float32)\n",
    "        )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c66cebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, dropout_rate: float):\n",
    "        super(GCNBlock, self).__init__()\n",
    "        self.conv = GCNConv(in_channels, out_channels)\n",
    "        self.bn = BatchNorm(out_channels)\n",
    "        self.dropout_rate = dropout_rate\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv(x, edge_index)\n",
    "        x = self.bn(x)\n",
    "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7ebab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, hidden_dims: list[int], dropout_rate: float):\n",
    "        super(Net, self).__init__()\n",
    "        self.gcns = nn.ModuleList()\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        for in_dim, out_dim in zip(self.hidden_dims[:-1], self.hidden_dims[1:]):\n",
    "            gcn_block = GCNBlock(in_channels=in_dim,\n",
    "                                 out_channels=out_dim,\n",
    "                                 dropout_rate=self.dropout_rate)\n",
    "            \n",
    "            self.gcns.append(gcn_block)\n",
    "\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dims[-1], self.hidden_dims[-1]//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(self.hidden_dims[-1]//2, self.hidden_dims[-1]//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(self.hidden_dims[-1]//2, 1)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        for block in self.gcns:\n",
    "            x = block(x, edge_index)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        out = self.output_layer(x).view(-1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ee35aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch)\n",
    "        loss = F.mse_loss(pred, batch.y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "        optimizer.step()\n",
    "    \n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    y_true, y_pred = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch)\n",
    "            y_true.append(batch.y.cpu().numpy())\n",
    "            y_pred.append(pred.cpu().numpy())\n",
    "            loss = F.mse_loss(pred, batch.y)\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "            \n",
    "    y_true = np.concatenate(y_true)    \n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    pearson_r, _ = pearsonr(y_true, y_pred)   \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    return total_loss / len(loader.dataset), rmse, pearson_r, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1433932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(dataset, model_class, train_one_epoch_fn, evaluate_fn,\n",
    "                device, generator, seed_worker, k_folds=5, batch_size=64, l2_norm=1e-4, momentum=0.97, epochs=None, \n",
    "                learning_rate=None, split_path=None, net_parameters=None, config=None):\n",
    "    \n",
    "    cv_results = {\n",
    "        f'fold_{key}':  {\n",
    "                    'loss_train': [],\n",
    "                    'loss_val': [],\n",
    "                    'loss_test': [],\n",
    "                    'val_rmse': [],\n",
    "                    'val_r': [],\n",
    "                    'val_mae': [],\n",
    "                    'test_rmse': [],\n",
    "                    'test_r': [],\n",
    "                    'test_mae': [],\n",
    "                    'epoch': []\n",
    "        } for key in range(0, k_folds)\n",
    "    }\n",
    "    mlflow.set_experiment('GCN_arch')\n",
    "    with mlflow.start_run(run_name=f'{config.TIMESTAMP}'):   \n",
    "        for fold in range(k_folds):\n",
    "            train_idx, val_idx, test_idx = [], [], []\n",
    "            data_split = json.load((split_path).open())\n",
    "            split_dict = data_split[fold]\n",
    "\n",
    "            for index, idx in enumerate(dataset.dataset['index'].astype(str)):\n",
    "                split = split_dict.get(idx)\n",
    "                \n",
    "                if split == \"train\":\n",
    "                    train_idx.append(index)\n",
    "                elif split == \"val\":\n",
    "                    val_idx.append(index)\n",
    "                elif split == \"test\":\n",
    "                    test_idx.append(index)\n",
    "\n",
    "            train_dataset = Subset(dataset, train_idx)\n",
    "            val_dataset = Subset(dataset, val_idx)\n",
    "            test_dataset = Subset(dataset, test_idx)\n",
    "            print(f'train: {len(train_dataset)}, val: {len(val_dataset)}, test: {len(test_dataset)}')\n",
    "            \n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                        shuffle=True, num_workers=4,\n",
    "                                        worker_init_fn=seed_worker, generator=generator)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
    "                                        shuffle=False, num_workers=4,\n",
    "                                        worker_init_fn=seed_worker, generator=generator)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                        shuffle=False, num_workers=4,\n",
    "                                        worker_init_fn=seed_worker, generator=generator)\n",
    "            \n",
    "            model = model_class(**net_parameters)\n",
    "            model.to(config.DEVICE)\n",
    "            \n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, \n",
    "                                            momentum=momentum, \n",
    "                                            weight_decay=l2_norm)\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
    "                                        factor=0.7, threshold=0.05, patience=8,\n",
    "                                        min_lr=1e-7)\n",
    "            for epoch in range(epochs):\n",
    "                train_loss = train_one_epoch_fn(model, train_loader, optimizer, device)\n",
    "                val_loss, val_rmse, val_r, val_mae = evaluate_fn(model, val_loader, device)\n",
    "\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "                mlflow.log_metric(f'Loss/Train_MSE_fold_{fold}', train_loss, epoch)\n",
    "                mlflow.log_metric(f'Loss/Validation_MSE_fold_{fold}', val_loss, epoch)\n",
    "                mlflow.log_metric(f'Validation/MAE_fold_{fold}', val_mae, epoch)\n",
    "                mlflow.log_metric(f'Validation/RMSE_fold_{fold}', val_rmse, epoch)\n",
    "                mlflow.log_metric(f'Validation/PearsonR_fold_{fold}', val_r, epoch)\n",
    "                mlflow.log_metric(f'LR/Learning Rate_fold_{fold}', optimizer.param_groups[0]['lr'], epoch)\n",
    "                \n",
    "                fold_key = f'fold_{fold}'\n",
    "                cv_results[fold_key]['loss_train'].append(train_loss)\n",
    "                cv_results[fold_key]['loss_val'].append(val_loss)\n",
    "                cv_results[fold_key]['val_rmse'].append(val_rmse)\n",
    "                cv_results[fold_key]['val_r'].append(val_r)\n",
    "                cv_results[fold_key]['val_mae'].append(val_mae)\n",
    "                cv_results[fold_key]['epoch'].append(epoch)\n",
    "\n",
    "                mlflow.pytorch.log_model(model, artifact_path=f'model_fold_{fold}')\n",
    "\n",
    "            _, test_rmse, test_r, test_mae = evaluate_fn(model, test_loader, device)\n",
    "\n",
    "            cv_results[fold_key]['test_rmse'].append(test_rmse)\n",
    "            cv_results[fold_key]['test_r'].append(test_r)            \n",
    "            cv_results[fold_key]['test_mae'].append(test_mae)\n",
    "                \n",
    "            calculate_test_results(cv_results=cv_results, epochs=epochs, mlflow=mlflow, model=model)\n",
    "\n",
    "\n",
    "def calculate_test_results(cv_results: dict, epochs: int, mlflow, model):\n",
    "    test_rmse_all = []\n",
    "    test_r_all = []\n",
    "    test_mae_all = []\n",
    "    for fold_key in cv_results.keys():\n",
    "        test_rmse_all.append(cv_results[fold_key]['test_rmse'])\n",
    "        test_r_all.append(cv_results[fold_key]['test_r'])\n",
    "        test_mae_all.append(cv_results[fold_key]['test_mae'])\n",
    "\n",
    "    test_rmse_array = np.array(test_rmse_all).flatten()\n",
    "    test_r_array = np.array(test_r_all).flatten() \n",
    "    test_mae_array = np.array(test_mae_all).flatten()\n",
    "\n",
    "    \n",
    "    mean_test_rmse = np.mean(test_rmse_array)\n",
    "    std_test_rmse = np.std(test_rmse_array)\n",
    "\n",
    "    mean_test_r = np.nanmean(test_r_array)\n",
    "    std_test_r = np.nanstd(test_r_array)\n",
    "    \n",
    "    mean_test_mae = np.mean(test_mae_array)\n",
    "    std_test_mae = np.std(test_mae_array)\n",
    "\n",
    "    mlflow.log_metrics({\n",
    "    \"Test/RMSE_mean\": mean_test_rmse,\n",
    "    \"Test/RMSE_std\": std_test_rmse,\n",
    "    \"Test/MAE_mean\": mean_test_mae,\n",
    "    \"Test/MAE_std\": std_test_mae,\n",
    "    \"Test/PearsonR_mean\": mean_test_r,\n",
    "    \"Test/PearsonR_std\": std_test_r\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9796c9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 19:37:32 INFO mlflow.tracking.fluent: Experiment with name 'GCN_arch' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 9058, val: 1214, test: 1212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 19:37:47 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/06 19:37:49 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:37:55 WARNING mlflow.utils.requirements_utils: Found torch-cluster version (1.6.3+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-cluster==1.6.3' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:37:55 WARNING mlflow.utils.requirements_utils: Found pyg-lib version (0.4.0+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'pyg-lib==0.4.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:37:55 WARNING mlflow.utils.requirements_utils: Found torch-scatter version (2.1.2+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-scatter==2.1.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:37:55 WARNING mlflow.utils.requirements_utils: Found torch-sparse version (0.6.18+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-sparse==0.6.18' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:37:55 WARNING mlflow.utils.requirements_utils: Found torch-spline-conv version (1.2.2+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-spline-conv==1.2.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:37:55 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/06 19:37:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/09/06 19:38:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/06 19:38:10 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:38:16 WARNING mlflow.utils.requirements_utils: Found torch-cluster version (1.6.3+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-cluster==1.6.3' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:38:16 WARNING mlflow.utils.requirements_utils: Found pyg-lib version (0.4.0+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'pyg-lib==0.4.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:38:16 WARNING mlflow.utils.requirements_utils: Found torch-scatter version (2.1.2+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-scatter==2.1.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:38:16 WARNING mlflow.utils.requirements_utils: Found torch-sparse version (0.6.18+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-sparse==0.6.18' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:38:16 WARNING mlflow.utils.requirements_utils: Found torch-spline-conv version (1.2.2+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-spline-conv==1.2.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:38:16 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/06 19:38:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/09/06 19:38:31 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/06 19:38:33 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:38:39 WARNING mlflow.utils.requirements_utils: Found torch-cluster version (1.6.3+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-cluster==1.6.3' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:38:39 WARNING mlflow.utils.requirements_utils: Found pyg-lib version (0.4.0+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'pyg-lib==0.4.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:38:39 WARNING mlflow.utils.requirements_utils: Found torch-scatter version (2.1.2+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-scatter==2.1.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:38:39 WARNING mlflow.utils.requirements_utils: Found torch-sparse version (0.6.18+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-sparse==0.6.18' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:38:39 WARNING mlflow.utils.requirements_utils: Found torch-spline-conv version (1.2.2+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-spline-conv==1.2.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 19:38:39 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/06 19:38:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/09/06 19:38:54 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/06 19:38:59 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:39:04 WARNING mlflow.utils.requirements_utils: Found torch-cluster version (1.6.3+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-cluster==1.6.3' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:39:04 WARNING mlflow.utils.requirements_utils: Found pyg-lib version (0.4.0+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'pyg-lib==0.4.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:39:04 WARNING mlflow.utils.requirements_utils: Found torch-scatter version (2.1.2+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-scatter==2.1.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:39:04 WARNING mlflow.utils.requirements_utils: Found torch-sparse version (0.6.18+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-sparse==0.6.18' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:39:04 WARNING mlflow.utils.requirements_utils: Found torch-spline-conv version (1.2.2+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-spline-conv==1.2.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:39:04 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/06 19:39:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/09/06 19:39:19 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/06 19:39:28 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:39:34 WARNING mlflow.utils.requirements_utils: Found torch-cluster version (1.6.3+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-cluster==1.6.3' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:39:34 WARNING mlflow.utils.requirements_utils: Found pyg-lib version (0.4.0+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'pyg-lib==0.4.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:39:34 WARNING mlflow.utils.requirements_utils: Found torch-scatter version (2.1.2+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-scatter==2.1.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:39:34 WARNING mlflow.utils.requirements_utils: Found torch-sparse version (0.6.18+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-sparse==0.6.18' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:39:34 WARNING mlflow.utils.requirements_utils: Found torch-spline-conv version (1.2.2+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-spline-conv==1.2.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:39:34 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/06 19:39:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/09/06 19:39:48 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/06 19:40:05 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:40:10 WARNING mlflow.utils.requirements_utils: Found torch-cluster version (1.6.3+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-cluster==1.6.3' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:40:10 WARNING mlflow.utils.requirements_utils: Found pyg-lib version (0.4.0+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'pyg-lib==0.4.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:40:10 WARNING mlflow.utils.requirements_utils: Found torch-scatter version (2.1.2+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-scatter==2.1.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 19:40:10 WARNING mlflow.utils.requirements_utils: Found torch-sparse version (0.6.18+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-sparse==0.6.18' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:40:10 WARNING mlflow.utils.requirements_utils: Found torch-spline-conv version (1.2.2+pt24cu124) contains a local version label (+pt24cu124). MLflow logged a pip requirement for this package as 'torch-spline-conv==1.2.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/06 19:40:10 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/09/06 19:40:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/09/06 19:40:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    }
   ],
   "source": [
    "generator = torch.Generator().manual_seed(config.RANDOM_SEED)\n",
    "\n",
    "hidden_dims = [30, 64, 128]\n",
    "\n",
    "net_params = {\n",
    "    'hidden_dims': hidden_dims,\n",
    "    'dropout_rate': 0.2\n",
    "    } \n",
    "\n",
    "run_params = {\n",
    "        'l2_norm': 1e-4,\n",
    "        'batch_size': 32,\n",
    "        'learning_rate': 1e-3, \n",
    "        'momentum': 0.97,\n",
    "        \"device\": config.DEVICE, \n",
    "        \"epochs\": 300,\n",
    "        \"k_folds\": 5\n",
    "    }\n",
    "\n",
    "cross_val_mean = cross_validation(\n",
    "        dataset=MeltDataset(), \n",
    "        net_parameters=net_params,\n",
    "        **run_params,\n",
    "        config=config,\n",
    "        model_class=Net, \n",
    "        train_one_epoch_fn=train_one_epoch, \n",
    "        evaluate_fn=evaluate,\n",
    "        split_path=config.DATA_PATH / 'melt_split.json',\n",
    "        generator=generator,\n",
    "        seed_worker=seed_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad7b3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2530f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".torch",
   "language": "python",
   "name": ".torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
